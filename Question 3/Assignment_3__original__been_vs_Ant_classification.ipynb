{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2410cd1d",
      "metadata": {
        "id": "2410cd1d"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCap-K1J5y0F",
        "outputId": "640d581b-bc45-453b-cb38-d510d3f35c8f"
      },
      "id": "HCap-K1J5y0F",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2"
      ],
      "metadata": {
        "id": "RpnsYrDDKh-v"
      },
      "id": "RpnsYrDDKh-v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2b399de4",
      "metadata": {
        "id": "2b399de4"
      },
      "source": [
        "# Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0119571",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0119571",
        "outputId": "a3f5fc66-513f-489b-8eda-626518eec4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "89614099",
      "metadata": {
        "id": "89614099"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3c538e46",
      "metadata": {
        "id": "3c538e46"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2774ac64",
      "metadata": {
        "id": "2774ac64"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "739a1bcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "739a1bcd",
        "outputId": "875b0b04-0c37-46d5-a1b9-b0c3769be5b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077105e1",
      "metadata": {
        "id": "077105e1"
      },
      "source": [
        "# Part 1 : Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e48c05de",
      "metadata": {
        "id": "e48c05de"
      },
      "source": [
        "# Processing the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fadcbd60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fadcbd60",
        "outputId": "de3177a0-e40e-4659-b055-c387c8956664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 244 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255\n",
        "        )\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(r\"/content/drive/MyDrive/happy_monk/assignment_3/dataset2/hymenoptera/train\",\n",
        "        target_size = (64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2d7612",
      "metadata": {
        "id": "aa2d7612"
      },
      "source": [
        "# Processing the test data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e44583f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e44583f",
        "outputId": "eb42e501-1380-4c53-e008-a4e77885f670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 153 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set =  test_datagen.flow_from_directory(\"/content/drive/MyDrive/happy_monk/assignment_3/dataset2/hymenoptera/val\",\n",
        "        target_size = (64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5775097",
      "metadata": {
        "id": "c5775097"
      },
      "source": [
        "# Part 2 : Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3efe5bd",
      "metadata": {
        "id": "f3efe5bd"
      },
      "source": [
        "# Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d957800d",
      "metadata": {
        "id": "d957800d"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e81f902",
      "metadata": {
        "id": "4e81f902"
      },
      "source": [
        "# Step 1 : convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f808043",
      "metadata": {
        "id": "8f808043"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,activation = 'relu', input_shape=[64,64,3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4013e489",
      "metadata": {
        "id": "4013e489"
      },
      "source": [
        "# step 2 : pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08dc477b",
      "metadata": {
        "id": "08dc477b"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2 ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8899095",
      "metadata": {
        "id": "b8899095"
      },
      "source": [
        "# Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9048779a",
      "metadata": {
        "id": "9048779a"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2 ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193ffca0",
      "metadata": {
        "id": "193ffca0"
      },
      "source": [
        "# step 3 : Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d51a7c",
      "metadata": {
        "id": "b4d51a7c"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b3c415",
      "metadata": {
        "id": "e0b3c415"
      },
      "source": [
        "# Step 4 : Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff77f0d",
      "metadata": {
        "id": "cff77f0d"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Dense(units=128,activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be3057cc",
      "metadata": {
        "id": "be3057cc"
      },
      "source": [
        "# Step 5 : Output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949aa174",
      "metadata": {
        "id": "949aa174"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e1e522",
      "metadata": {
        "id": "12e1e522"
      },
      "source": [
        "# Part 3 : Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90f5c9aa",
      "metadata": {
        "id": "90f5c9aa"
      },
      "source": [
        "# compile the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad16f81",
      "metadata": {
        "id": "bad16f81"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a86b2117",
      "metadata": {
        "id": "a86b2117"
      },
      "source": [
        "# Trianing the CNN on the Training data set and evaluation it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e455a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89e455a4",
        "outputId": "f87b68ef-f5ee-493d-e02c-09fb78d0b4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "8/8 [==============================] - 196s 25s/step - loss: 0.8433 - accuracy: 0.5000 - val_loss: 0.7456 - val_accuracy: 0.4575\n",
            "Epoch 2/25\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.6803 - accuracy: 0.5656 - val_loss: 0.6762 - val_accuracy: 0.5556\n",
            "Epoch 3/25\n",
            "8/8 [==============================] - 2s 315ms/step - loss: 0.6637 - accuracy: 0.5697 - val_loss: 0.6697 - val_accuracy: 0.5686\n",
            "Epoch 4/25\n",
            "8/8 [==============================] - 2s 325ms/step - loss: 0.6347 - accuracy: 0.6639 - val_loss: 0.6874 - val_accuracy: 0.5359\n",
            "Epoch 5/25\n",
            "8/8 [==============================] - 2s 315ms/step - loss: 0.5768 - accuracy: 0.7131 - val_loss: 0.6951 - val_accuracy: 0.5621\n",
            "Epoch 6/25\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.5446 - accuracy: 0.7254 - val_loss: 0.7762 - val_accuracy: 0.5556\n",
            "Epoch 7/25\n",
            "8/8 [==============================] - 2s 308ms/step - loss: 0.4834 - accuracy: 0.7623 - val_loss: 0.6582 - val_accuracy: 0.6667\n",
            "Epoch 8/25\n",
            "8/8 [==============================] - 2s 313ms/step - loss: 0.4383 - accuracy: 0.8156 - val_loss: 0.6983 - val_accuracy: 0.6340\n",
            "Epoch 9/25\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.6505 - val_accuracy: 0.6405\n",
            "Epoch 10/25\n",
            "8/8 [==============================] - 2s 315ms/step - loss: 0.3398 - accuracy: 0.8934 - val_loss: 0.6851 - val_accuracy: 0.6471\n",
            "Epoch 11/25\n",
            "8/8 [==============================] - 2s 302ms/step - loss: 0.2932 - accuracy: 0.8934 - val_loss: 0.8195 - val_accuracy: 0.6471\n",
            "Epoch 12/25\n",
            "8/8 [==============================] - 2s 318ms/step - loss: 0.2659 - accuracy: 0.8934 - val_loss: 0.7256 - val_accuracy: 0.6340\n",
            "Epoch 13/25\n",
            "8/8 [==============================] - 2s 317ms/step - loss: 0.2149 - accuracy: 0.9262 - val_loss: 0.7928 - val_accuracy: 0.6340\n",
            "Epoch 14/25\n",
            "8/8 [==============================] - 3s 352ms/step - loss: 0.1644 - accuracy: 0.9508 - val_loss: 0.9325 - val_accuracy: 0.6667\n",
            "Epoch 15/25\n",
            "8/8 [==============================] - 2s 311ms/step - loss: 0.1508 - accuracy: 0.9508 - val_loss: 0.8507 - val_accuracy: 0.6078\n",
            "Epoch 16/25\n",
            "8/8 [==============================] - 2s 314ms/step - loss: 0.1031 - accuracy: 0.9836 - val_loss: 0.9667 - val_accuracy: 0.6078\n",
            "Epoch 17/25\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 0.0717 - accuracy: 0.9877 - val_loss: 1.1667 - val_accuracy: 0.5817\n",
            "Epoch 18/25\n",
            "8/8 [==============================] - 2s 310ms/step - loss: 0.0575 - accuracy: 0.9918 - val_loss: 1.1230 - val_accuracy: 0.6013\n",
            "Epoch 19/25\n",
            "8/8 [==============================] - 2s 312ms/step - loss: 0.0408 - accuracy: 0.9959 - val_loss: 1.1490 - val_accuracy: 0.6209\n",
            "Epoch 20/25\n",
            "8/8 [==============================] - 2s 308ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.6013\n",
            "Epoch 21/25\n",
            "8/8 [==============================] - 2s 312ms/step - loss: 0.0292 - accuracy: 0.9959 - val_loss: 1.3064 - val_accuracy: 0.6078\n",
            "Epoch 22/25\n",
            "8/8 [==============================] - 2s 311ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.3789 - val_accuracy: 0.5948\n",
            "Epoch 23/25\n",
            "8/8 [==============================] - 2s 319ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.4307 - val_accuracy: 0.6078\n",
            "Epoch 24/25\n",
            "8/8 [==============================] - 2s 312ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5160 - val_accuracy: 0.6013\n",
            "Epoch 25/25\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5724 - val_accuracy: 0.6078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd678666fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "cnn.fit(x = train_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a30846d5",
      "metadata": {
        "id": "a30846d5"
      },
      "source": [
        "# Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "945TSIUkK9Zg"
      },
      "id": "945TSIUkK9Zg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Addz7khGLJav",
        "outputId": "f3ba0ccc-bf3b-48b5-89b6-15827cd85ba6"
      },
      "id": "Addz7khGLJav",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement OpenCV (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for OpenCV\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b4f6e7",
      "metadata": {
        "id": "f3b4f6e7"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "test_image = tf.keras.utils.load_img ('/content/drive/MyDrive/happy_monk/assignment_3/dataset2/hymenoptera/val/bees/149973093_da3c446268.jpg',target_size = (64,64))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc624a5",
      "metadata": {
        "id": "5fc624a5"
      },
      "outputs": [],
      "source": [
        "#img_to_array function\n",
        "#Converts a PIL Image instance to a Numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec00d94c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec00d94c",
        "outputId": "7c4d9ebb-fa09-4ff7-a3df-82cfd448d056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "test_image = tf.keras.utils.img_to_array(test_image)\n",
        "#our network is trained for batch of 32 images but here we are sending only one image to predect so we need to create fake another  daimensions array using numpy library\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "#the output will be in 0 or 1 so we need encode for what zero and one indicate in training data set\n",
        "train_set.class_indices\n",
        "#result also contain batch size so it will be a 2D array\n",
        "# in the total batch there is only one image is to be predicted other data is fake ,created by numpy library\n",
        "\n",
        "if result[0][0]== 1:\n",
        "    prediction = 'ant'\n",
        "else:\n",
        "    prediction = 'bees'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed230c50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed230c50",
        "outputId": "357e96c1-191e-4cdf-864d-10a8550ab509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bees\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bb84de60",
      "metadata": {
        "id": "bb84de60"
      },
      "outputs": [],
      "source": [
        "#For Non Augmented data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255\n",
        "        )\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(r\"/content/drive/MyDrive/happy_monk/assignment_3/Augmented_dataset/train\",\n",
        "        target_size = (64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTd8DnTgTIYF",
        "outputId": "72f67fc7-76f2-4f52-87ff-d5c8b0396119"
      },
      "id": "bTd8DnTgTIYF",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 199 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set =  test_datagen.flow_from_directory(\"/content/drive/MyDrive/happy_monk/assignment_3/Augmented_dataset/val\",\n",
        "        target_size = (64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rMiSupTd9Ie",
        "outputId": "baa93b79-26ca-4761-9b1d-9ae12198bbac"
      },
      "id": "-rMiSupTd9Ie",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "-txaa5g5gPa0"
      },
      "id": "-txaa5g5gPa0",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,activation = 'relu', input_shape=[64,64,3]))"
      ],
      "metadata": {
        "id": "OLnPcoZBgQWk"
      },
      "id": "OLnPcoZBgQWk",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2 ))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2 ))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128,activation=\"relu\"))\n",
        "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "cMgyVNRVgUlp"
      },
      "id": "cMgyVNRVgUlp",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Qz52-dDDgfZo"
      },
      "id": "Qz52-dDDgfZo",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = train_set, validation_data = test_set, epochs = 25)\n",
        "cnn.save(\"ontent/drive/MyDrive/happy_monk/assignment_3/Augmented_dataset//c\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG9IAMgugxjw",
        "outputId": "c6151b4b-a65a-4702-caa3-8d3dab9b2166"
      },
      "id": "bG9IAMgugxjw",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "7/7 [==============================] - 3s 388ms/step - loss: 0.6931 - accuracy: 0.5628 - val_loss: 0.6772 - val_accuracy: 0.5250\n",
            "Epoch 2/25\n",
            "7/7 [==============================] - 3s 398ms/step - loss: 0.6612 - accuracy: 0.5879 - val_loss: 0.6733 - val_accuracy: 0.6062\n",
            "Epoch 3/25\n",
            "7/7 [==============================] - 3s 408ms/step - loss: 0.6317 - accuracy: 0.6432 - val_loss: 0.7045 - val_accuracy: 0.5312\n",
            "Epoch 4/25\n",
            "7/7 [==============================] - 3s 395ms/step - loss: 0.6206 - accuracy: 0.6482 - val_loss: 0.6769 - val_accuracy: 0.5437\n",
            "Epoch 5/25\n",
            "7/7 [==============================] - 3s 410ms/step - loss: 0.5828 - accuracy: 0.6734 - val_loss: 0.6970 - val_accuracy: 0.6250\n",
            "Epoch 6/25\n",
            "7/7 [==============================] - 3s 399ms/step - loss: 0.5769 - accuracy: 0.6784 - val_loss: 0.7364 - val_accuracy: 0.5437\n",
            "Epoch 7/25\n",
            "7/7 [==============================] - 4s 516ms/step - loss: 0.5469 - accuracy: 0.7035 - val_loss: 0.6981 - val_accuracy: 0.6438\n",
            "Epoch 8/25\n",
            "7/7 [==============================] - 3s 396ms/step - loss: 0.4963 - accuracy: 0.7739 - val_loss: 0.7605 - val_accuracy: 0.5688\n",
            "Epoch 9/25\n",
            "7/7 [==============================] - 3s 426ms/step - loss: 0.4629 - accuracy: 0.7990 - val_loss: 0.7797 - val_accuracy: 0.5562\n",
            "Epoch 10/25\n",
            "7/7 [==============================] - 3s 393ms/step - loss: 0.4162 - accuracy: 0.8442 - val_loss: 0.8801 - val_accuracy: 0.5500\n",
            "Epoch 11/25\n",
            "7/7 [==============================] - 3s 395ms/step - loss: 0.3904 - accuracy: 0.8342 - val_loss: 0.7785 - val_accuracy: 0.5625\n",
            "Epoch 12/25\n",
            "7/7 [==============================] - 3s 432ms/step - loss: 0.4217 - accuracy: 0.8090 - val_loss: 0.7528 - val_accuracy: 0.5562\n",
            "Epoch 13/25\n",
            "7/7 [==============================] - 3s 385ms/step - loss: 0.3288 - accuracy: 0.8844 - val_loss: 0.7468 - val_accuracy: 0.6062\n",
            "Epoch 14/25\n",
            "7/7 [==============================] - 3s 400ms/step - loss: 0.2836 - accuracy: 0.9095 - val_loss: 0.9549 - val_accuracy: 0.5938\n",
            "Epoch 15/25\n",
            "7/7 [==============================] - 3s 391ms/step - loss: 0.2428 - accuracy: 0.9296 - val_loss: 0.8791 - val_accuracy: 0.5500\n",
            "Epoch 16/25\n",
            "7/7 [==============================] - 3s 404ms/step - loss: 0.2120 - accuracy: 0.9397 - val_loss: 0.9012 - val_accuracy: 0.5500\n",
            "Epoch 17/25\n",
            "7/7 [==============================] - 3s 396ms/step - loss: 0.1684 - accuracy: 0.9497 - val_loss: 0.9129 - val_accuracy: 0.5500\n",
            "Epoch 18/25\n",
            "7/7 [==============================] - 3s 396ms/step - loss: 0.1259 - accuracy: 0.9799 - val_loss: 0.9935 - val_accuracy: 0.5813\n",
            "Epoch 19/25\n",
            "7/7 [==============================] - 3s 394ms/step - loss: 0.1063 - accuracy: 0.9749 - val_loss: 1.0568 - val_accuracy: 0.6000\n",
            "Epoch 20/25\n",
            "7/7 [==============================] - 3s 395ms/step - loss: 0.0872 - accuracy: 0.9799 - val_loss: 1.1165 - val_accuracy: 0.6062\n",
            "Epoch 21/25\n",
            "7/7 [==============================] - 3s 403ms/step - loss: 0.0714 - accuracy: 0.9899 - val_loss: 1.3052 - val_accuracy: 0.5625\n",
            "Epoch 22/25\n",
            "7/7 [==============================] - 3s 401ms/step - loss: 0.0832 - accuracy: 0.9899 - val_loss: 1.1713 - val_accuracy: 0.5813\n",
            "Epoch 23/25\n",
            "7/7 [==============================] - 3s 406ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.5750\n",
            "Epoch 24/25\n",
            "7/7 [==============================] - 3s 437ms/step - loss: 0.0426 - accuracy: 0.9950 - val_loss: 1.2073 - val_accuracy: 0.5875\n",
            "Epoch 25/25\n",
            "7/7 [==============================] - 3s 395ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 1.3295 - val_accuracy: 0.6313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tRURSgjZg1E_"
      },
      "id": "tRURSgjZg1E_",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZnXCqNlmeDc"
      },
      "id": "UZnXCqNlmeDc",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2c83peXprxV"
      },
      "id": "a2c83peXprxV",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zoQeH5MDAQlf"
      },
      "id": "zoQeH5MDAQlf",
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}